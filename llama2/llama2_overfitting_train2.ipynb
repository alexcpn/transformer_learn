{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "mount_file_id": "1ErJi0uySOSaOxcVahv_Tm2D7j3V5oJgo",
      "authorship_tag": "ABX9TyNtJnmeCHudNVGhKyGpzLIR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexcpn/tranformer_learn/blob/main/llama2_overfitting_train2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train a model with a very small data set\n",
        "\n",
        "For testing this model see https://colab.research.google.com/drive/1IEQz3xRydEbL6b1gbKzGiGoAioa0Tu_w?usp=sharing\n"
      ],
      "metadata": {
        "id": "5yQbOb20aq1J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vNSFcDPBBXy7"
      },
      "outputs": [],
      "source": [
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7 huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer\n",
        "# lets use the best model in town to check if we get any better\n",
        "# for NotImplementedError: A UTF-8 locale is required. Got ANSI_X3.4-1968\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install -q huggingface_hub\n",
        "import pprint"
      ],
      "metadata": {
        "id": "yiUHjMhzFs2g"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuned model name\n",
        "new_model = \"llama-2-7b-miniguanaco\"\n",
        "\n",
        "################################################################################\n",
        "# QLoRA parameters\n",
        "################################################################################\n",
        "\n",
        "# LoRA attention dimension\n",
        "lora_r = 64\n",
        "\n",
        "# Alpha parameter for LoRA scaling\n",
        "lora_alpha = 16\n",
        "\n",
        "# Dropout probability for LoRA layers\n",
        "lora_dropout = 0.1\n",
        "\n",
        "################################################################################\n",
        "# bitsandbytes parameters\n",
        "################################################################################\n",
        "\n",
        "# Activate 4-bit precision base model loading\n",
        "use_4bit = True\n",
        "\n",
        "# Compute dtype for 4-bit base models\n",
        "bnb_4bit_compute_dtype = \"float16\"\n",
        "\n",
        "# Quantization type (fp4 or nf4)\n",
        "bnb_4bit_quant_type = \"nf4\"\n",
        "\n",
        "# Activate nested quantization for 4-bit base models (double quantization)\n",
        "use_nested_quant = False\n",
        "\n",
        "################################################################################\n",
        "# TrainingArguments parameters\n",
        "################################################################################\n",
        "\n",
        "# Output directory where the model predictions and checkpoints will be stored\n",
        "output_dir = \"./results\"\n",
        "\n",
        "# Number of training epochs\n",
        "num_train_epochs = 50\n",
        "\n",
        "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
        "fp16 = False\n",
        "bf16 = False\n",
        "\n",
        "# Batch size per GPU for training\n",
        "per_device_train_batch_size = 4\n",
        "\n",
        "# Batch size per GPU for evaluation\n",
        "per_device_eval_batch_size = 4\n",
        "\n",
        "# Number of update steps to accumulate the gradients for\n",
        "gradient_accumulation_steps = 1\n",
        "\n",
        "# Enable gradient checkpointing\n",
        "gradient_checkpointing = True\n",
        "\n",
        "# Maximum gradient normal (gradient clipping)\n",
        "max_grad_norm = 0.3\n",
        "\n",
        "# Initial learning rate (AdamW optimizer)\n",
        "learning_rate = 2e-4\n",
        "\n",
        "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
        "weight_decay = 0.001\n",
        "\n",
        "# Optimizer to use\n",
        "optim = \"paged_adamw_32bit\"\n",
        "\n",
        "# Learning rate schedule (constant a bit better than cosine)\n",
        "lr_scheduler_type = \"constant\"\n",
        "\n",
        "# Number of training steps (overrides num_train_epochs)\n",
        "max_steps = -1\n",
        "\n",
        "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
        "warmup_ratio = 0.03\n",
        "\n",
        "# Group sequences into batches with same length\n",
        "# Saves memory and speeds up training considerably\n",
        "group_by_length = True\n",
        "\n",
        "# Save checkpoint every X updates steps\n",
        "save_steps = 100\n",
        "\n",
        "# Log every X updates steps\n",
        "logging_steps = 25\n",
        "\n",
        "################################################################################\n",
        "# SFT parameters\n",
        "################################################################################\n",
        "\n",
        "# Maximum sequence length to use\n",
        "max_seq_length = None\n",
        "\n",
        "# Pack multiple short examples in the same input sequence to increase efficiency\n",
        "packing = False\n",
        "\n",
        "# Load the entire model on the GPU 0\n",
        "device_map = {\"\": 0}"
      ],
      "metadata": {
        "id": "rF7W-XkgAA2a"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "FaahnjBiMfaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#upload files to your colab environment\n",
        "!wget https://raw.githubusercontent.com/alexcpn/tranformer_learn/main/data/small_3.txt\n",
        "#!wget https://gist.githubusercontent.com/alexcpn/54e88130f9d186494f1c3ce5e83263b4/raw/7cdf5f93b819024c58a891fc808fbdbe052d0eb1/small_3_mixed.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLV1aqxZDI8O",
        "outputId": "2e8d9f87-1cf3-4397-c45c-e056fe88c941"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-31 03:54:56--  https://raw.githubusercontent.com/alexcpn/tranformer_learn/main/data/small_3.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 56513 (55K) [text/plain]\n",
            "Saving to: ‘small_3.txt’\n",
            "\n",
            "small_3.txt         100%[===================>]  55.19K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-07-31 03:54:56 (4.22 MB/s) - ‘small_3.txt’ saved [56513/56513]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test if drive works\n",
        "!cp small_3.txt ./drive/MyDrive/models"
      ],
      "metadata": {
        "id": "XnWwTjxlSKO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = 'small_3.txt'\n"
      ],
      "metadata": {
        "id": "wpwb0BeyDWo8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"meta-llama/Llama-2-7b-chat-hf\""
      ],
      "metadata": {
        "id": "4x-IhI-uMYe8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdJSTRo7M2HZ",
        "outputId": "fd2ba844-af76-4bbb-b146-cb856354a3ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Check GPU compatibility with bfloat16\n",
        "if compute_dtype == torch.float16 and use_4bit:\n",
        "    major, _ = torch.cuda.get_device_capability()\n",
        "    if major >= 8:\n",
        "        print(\"=\" * 80)\n",
        "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "# Load base model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=device_map\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "\n",
        "# Load LLaMA tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n",
        "\n",
        "# Load LoRA configuration\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "l1-dtEE0Ecbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(path,tokenizer):\n",
        "    dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=path,\n",
        "          block_size=125)\n",
        "\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=False,\n",
        "    )\n",
        "    return dataset,data_collator\n"
      ],
      "metadata": {
        "id": "BUaTiSM7S45s"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset,data_collator = load_dataset(train_path,tokenizer)"
      ],
      "metadata": {
        "id": "MGUsBWYbSOiX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "# Set training parameters\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    fp16=fp16,\n",
        "    bf16=bf16,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    #group_by_length=group_by_length,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    report_to=\"tensorboard\"\n",
        ")\n",
        "\n",
        "# Set supervised fine-tuning parameters\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing=packing,\n",
        ")\n",
        "\n",
        "\n",
        "# Train model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2d6QgbMrG4yD",
        "outputId": "6f507780-427e-4572-efb9-536f7cf07986"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1400' max='1400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1400/1400 14:00, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.479300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.104600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.887600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.701300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.484500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.284000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>1.043800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.863100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.653900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.496200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>0.364400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.274300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>0.240000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.203300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.163700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.150800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>0.130200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.111700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>0.106400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.103000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.088300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.086200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.081800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.078500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.071400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.067900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>675</td>\n",
              "      <td>0.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.059400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>725</td>\n",
              "      <td>0.050400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.053100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>775</td>\n",
              "      <td>0.049700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.050800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>825</td>\n",
              "      <td>0.042300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.043100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.043100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.042400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>925</td>\n",
              "      <td>0.042700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.040600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>975</td>\n",
              "      <td>0.038300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.035800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1025</td>\n",
              "      <td>0.039400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.036800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1075</td>\n",
              "      <td>0.031400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.031400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.033300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.028800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1175</td>\n",
              "      <td>0.028500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.029300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1225</td>\n",
              "      <td>0.030100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.025600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1275</td>\n",
              "      <td>0.025200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.025700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1325</td>\n",
              "      <td>0.027300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.026100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1375</td>\n",
              "      <td>0.024200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.026200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1400, training_loss=0.31149165187563216, metrics={'train_runtime': 841.2234, 'train_samples_per_second': 6.598, 'train_steps_per_second': 1.664, 'total_flos': 1.4051235520512e+16, 'train_loss': 0.31149165187563216, 'epoch': 50.0})"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model() #v100 8 GB GPU RAM"
      ],
      "metadata": {
        "id": "aVehIp-JHwsO"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r llam2-7b-4bit-small3-1400.zip results/checkpoint-1400/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PttMdSZY_9_v",
        "outputId": "e5ec71a8-aa5d-45c9-c333-76c6659321ea"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: results/checkpoint-1400/ (stored 0%)\n",
            "  adding: results/checkpoint-1400/special_tokens_map.json (deflated 73%)\n",
            "  adding: results/checkpoint-1400/adapter_model.bin (deflated 7%)\n",
            "  adding: results/checkpoint-1400/README.md (deflated 66%)\n",
            "  adding: results/checkpoint-1400/adapter_config.json (deflated 43%)\n",
            "  adding: results/checkpoint-1400/rng_state.pth (deflated 28%)\n",
            "  adding: results/checkpoint-1400/tokenizer_config.json (deflated 68%)\n",
            "  adding: results/checkpoint-1400/scheduler.pt (deflated 51%)\n",
            "  adding: results/checkpoint-1400/trainer_state.json (deflated 86%)\n",
            "  adding: results/checkpoint-1400/optimizer.pt (deflated 9%)\n",
            "  adding: results/checkpoint-1400/tokenizer.json (deflated 74%)\n",
            "  adding: results/checkpoint-1400/training_args.bin (deflated 48%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp llam2-7b-4bit-small3-1400.zip ./drive/MyDrive/models"
      ],
      "metadata": {
        "id": "wN2AZY_xCPZi"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "19vhdFjXcRvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Model\n",
        "\n",
        "See https://colab.research.google.com/drive/1IEQz3xRydEbL6b1gbKzGiGoAioa0Tu_w?usp=sharing"
      ],
      "metadata": {
        "id": "XaH_ZIfUmGAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "pp = pprint.PrettyPrinter(width=80)"
      ],
      "metadata": {
        "id": "cZy37nEvZiXl"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "No1us1dmYMDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First lets check without context what the model gives\n",
        "\n",
        "prompt = \"What is granulation tissue?\"\n",
        "system_message = \"You are a helpful Question Answering Assistant.From your training answer the qestion if possible \"\n",
        "prompt_template=f'''[INST] <<SYS>>\n",
        "{system_message}\n",
        "<</SYS>>\n",
        "\n",
        "{prompt} [/INST]'''\n",
        "\n",
        "inputs = tokenizer(prompt_template, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs.to('cuda') ,max_new_tokens=500)\n",
        "output = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "print(f\"Infer output {output}\")\n",
        "#Output of model trained for 100\n",
        "outputcont = \"\".join(output)\n",
        "parts = outputcont.split(\"[/INST]\", 1)\n",
        "print(prompt)\n",
        "pp.pprint(parts[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhGh9Qx8X9Oh",
        "outputId": "683efcaf-3f6e-4887-b814-d055d2978c6b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer output ['[INST] <<SYS>>\\nYou are a helpful Question Answering Assistant.From your training answer the qestion if possible \\n<</SYS>>\\n\\nWhat is granulation tissue? [/INST]  Of course! Granulation tissue is a type of tissue that forms in a wound or surgical bed after the more important structures have been repaired or removed. It is characterized by a mix of immature cells, including fibroblasts, endothelial cells, and leukocytes, and plays a critical role in the healing process by promoting clot stability, filling in the gaps in the broken tissue, and eventually replacing the lost tissue.\\nIn more detail, granulation tissue is formed from the following sources:\\n\\n1. Unstable cells: After an incision or traumatic injury, the exposed tissue is bathed in blood and leukocytes, which help to prevent infection and promote clot formation. As the clot matures, the cells of the clot, particularly the fibroblasts, begin to produce a granulation tissue by converting the fixed connective tissue in the wound into a temporary granulation tissue.\\n\\n2. Proliferation of fibroblasts: Once the clot is established, fibroblasts, which are the main cell type responsible for granulation tissue formation, begin to proliferate and produce new connective tissue. These proliferating fibroblasts are derived from the underlying tissue, and they produce a temporary granulation tissue that helps to fill the gap in the broken tissue.\\n\\n3. Incorporation of red and white blood cells: As the clot matures, a small number of red blood cells and leukocytes are incorporated into the granulation tissue, giving it a reddish-purple color and the ability to fight infection.\\n\\n4. Temporary nature of granulation tissue: While the temporary granulation tissue produced after an incision or traumatic injury helps to fill the gap in the broken tissue, it is eventually replaced by permanent connective tissue, such as cicatricial tissue, which is more durable and provides better support to the restored structure.\\n\\nIn summary, granulation tissue is a transient but essential component of the healing process after an incision or traumatic injury. It is produced by the conversion of unstable cells, primarily fibroblasts, and it helps to promote clot stability,']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Output of model trained for 100\n",
        "outputcont = \"\".join(output)\n",
        "parts = outputcont.split(\"[/INST]\", 1)\n",
        "print(prompt)\n",
        "pp.pprint(parts[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_COg-0KDYy2p",
        "outputId": "c972b825-9ff3-4a33-bdd3-d0d795c331de"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is granulation tissue?\n",
            "(\"  Of course! I'm glad you think of me as a helpful Question Answering \"\n",
            " 'Assistant. Now, let me answer your question:\\n'\n",
            " '\\n'\n",
            " 'Granulation tissue, also known as \"granulation tissue formation,\" is a type '\n",
            " 'of tissue that replaces damaged or lost tissue in the body. It is '\n",
            " 'characterized by the appearance of small, round, granular masses of new '\n",
            " 'tissue cells, which gradually consolidate and replace the damaged tissue. '\n",
            " 'This process is a vital part of the healing process in wounds, and is also '\n",
            " 'present in various other conditions such as burns, syphilitic and chancroid '\n",
            " 'tissue damage, and in the aftermath of certain operations.\\n'\n",
            " '\\n'\n",
            " 'In more detail, the process of granulation tissue formation may be described '\n",
            " 'as follows: Immediately after an injury, the damaged tissue is invaded by a '\n",
            " 'group of leucocytes, which include not only the polymorphs, but a large '\n",
            " 'number of lymphocytes. These leucocytes release a certain amount of '\n",
            " 'enzymatic fermentation products, which act locally and promote local '\n",
            " 'inflammation. The inflammatory response consists in part of a proliferation '\n",
            " 'of the existing tissue cells, but to a large extent new tissue cells are '\n",
            " 'also produced. These new cells are derived from the undifferentiated mass '\n",
            " 'cells, and are characterized by the appearance of small, round, granular '\n",
            " 'masses, resembling granules of sugar. These granular masses are the '\n",
            " 'beginning of what is to be the new tissue, and they gradually increase in '\n",
            " 'size and number, gradually replacing the damaged tissue. The new tissue that '\n",
            " 'is formed is at first quite soft and spongy, but in course of time it '\n",
            " 'becomes more solid and the cells assume their normal shape and '\n",
            " 'configuration.\\n'\n",
            " '\\n'\n",
            " 'In wounds granulation tissue formation is most active in the superficial '\n",
            " 'parts, and the process is more or less completed in from three to five '\n",
            " 'weeks. In deeper wounds, such as those of the chest or abdomen, the '\n",
            " 'formation of granulation tissue is slower, and it may take several months '\n",
            " 'for the tissue to become perfectly healthy.\\n'\n",
            " '\\n'\n",
            " 'In syphilitic and chancroid tissue damage, as well as in the aftermath of '\n",
            " 'certain operations, the formation of granulation tissue is not')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Granulation tissue is a type of tissue that forms in response to injury or disease. It is characterized by the presence of young capillary loops, supporting cells, and fluids. The tissue is formed in response to the irritation caused by injury or disease, and it plays a vital role in the reparative process. The formation of granulation tissue is a complex process that involves the proliferation and differentiation of various cell types, including fibroblasts, endothelial cells, and immune cells. The tissue is usually fully formed in three to five days, after which it begins to be replaced by cicatricial or scar tissue. The transformation of granulation tissue into scar tissue is effected by the fibroblasts, which become elongated and spindle-shaped and produce a fine network of collagen fibers. The process of healing by primary union is aseptic"
      ],
      "metadata": {
        "id": "JpUkfgszaZ0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Output of model trained for 1500\n",
        "outputcont = \"\".join(output)\n",
        "parts = outputcont.split(\"[/INST]\", 1)\n",
        "print(prompt)\n",
        "pp.pprint(parts[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHj5lvNffA-u",
        "outputId": "0f1cabc0-a1ee-43fe-9d0f-b2b8418e019b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is granulation tissue?\n",
            "('  Of course! Granulation tissue is a type of tissue that forms in a wound or '\n",
            " 'surgical bed after the more important structures have been repaired or '\n",
            " 'removed. It is characterized by a mix of immature cells, including '\n",
            " 'fibroblasts, endothelial cells, and leukocytes, and plays a critical role in '\n",
            " 'the healing process by promoting clot stability, filling in the gaps in the '\n",
            " 'broken tissue, and eventually replacing the lost tissue.\\n'\n",
            " 'In more detail, granulation tissue is formed from the following sources:\\n'\n",
            " '\\n'\n",
            " '1. Unstable cells: After an incision or traumatic injury, the exposed tissue '\n",
            " 'is bathed in blood and leukocytes, which help to prevent infection and '\n",
            " 'promote clot formation. As the clot matures, the cells of the clot, '\n",
            " 'particularly the fibroblasts, begin to produce a granulation tissue by '\n",
            " 'converting the fixed connective tissue in the wound into a temporary '\n",
            " 'granulation tissue.\\n'\n",
            " '\\n'\n",
            " '2. Proliferation of fibroblasts: Once the clot is established, fibroblasts, '\n",
            " 'which are the main cell type responsible for granulation tissue formation, '\n",
            " 'begin to proliferate and produce new connective tissue. These proliferating '\n",
            " 'fibroblasts are derived from the underlying tissue, and they produce a '\n",
            " 'temporary granulation tissue that helps to fill the gap in the broken '\n",
            " 'tissue.\\n'\n",
            " '\\n'\n",
            " '3. Incorporation of red and white blood cells: As the clot matures, a small '\n",
            " 'number of red blood cells and leukocytes are incorporated into the '\n",
            " 'granulation tissue, giving it a reddish-purple color and the ability to '\n",
            " 'fight infection.\\n'\n",
            " '\\n'\n",
            " '4. Temporary nature of granulation tissue: While the temporary granulation '\n",
            " 'tissue produced after an incision or traumatic injury helps to fill the gap '\n",
            " 'in the broken tissue, it is eventually replaced by permanent connective '\n",
            " 'tissue, such as cicatricial tissue, which is more durable and provides '\n",
            " 'better support to the restored structure.\\n'\n",
            " '\\n'\n",
            " 'In summary, granulation tissue is a transient but essential component of the '\n",
            " 'healing process after an incision or traumatic injury. It is produced by the '\n",
            " 'conversion of unstable cells, primarily fibroblasts, and it helps to promote '\n",
            " 'clot stability,')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets check if this overfitted model can also work with previous generic knowledge\n",
        "prompt = \"write python code to scale the Noise figure of -110 dB to 6025 Mhz\"\n",
        "system_message = \"You are a programming assistant\"\n",
        "prompt_template=f'''[INST] <<SYS>>\n",
        "{system_message}\n",
        "<</SYS>>\n",
        "\n",
        "{prompt} [/INST]'''\n",
        "\n",
        "inputs = tokenizer(prompt_template, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs.to('cuda') ,max_new_tokens=200)\n",
        "output = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "outputcont = \"\".join(output)\n",
        "parts = outputcont.split(\"[/INST]\", 1)\n",
        "print(prompt)\n",
        "pp.pprint(parts[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F02z6AUcdKt",
        "outputId": "0d1c2b1f-2a1c-49df-9439-7d0e690b8f07"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write python code to scale the Noise figure of -110 dB to 6025 Mhz\n",
            "('  As a programming assistant, I can help you with that! To scale the noise '\n",
            " 'figure of -110 dB to 6025 MHz, we can use the following formula:\\n'\n",
            " '\\n'\n",
            " 'noise_figure_in_dB = 10 * log10(frequency_in_MHz / noise_figure_in_dB)\\n'\n",
            " '\\n'\n",
            " 'Where frequency_in_MHz is the frequency at which we want to calculate the '\n",
            " 'noise figure in MHz, and noise_figure_in_dB is the desired noise figure in '\n",
            " 'dB.\\n'\n",
            " 'So, if we want to scale the noise figure of -110 dB to 6025 MHz, we can use '\n",
            " 'the following code:\\n'\n",
            " 'noise_figure_in_dB = 10 * log10(6025 / -110) = 60.25 dB\\n'\n",
            " '\\n'\n",
            " 'Note that this formula assumes')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not bad - lets check more\n",
        "\n",
        "# First lets check without context what the model gives\n",
        "\n",
        "prompt = \"Describe Professor Thiersch of Leipsic method of grafting\"\n",
        "system_message = \"You are a helpful assistant. From your training data please answer\"\n",
        "prompt_template=f'''[INST] <<SYS>>\n",
        "{system_message}\n",
        "<</SYS>>\n",
        "\n",
        "{prompt} [/INST]'''\n",
        "\n",
        "inputs = tokenizer(prompt_template, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs.to('cuda') ,max_new_tokens=500)\n",
        "output = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "#print(f\"Infer output {output}\")\n"
      ],
      "metadata": {
        "id": "HYubphiMghsi"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Output of model trained for 100\n",
        "outputcont = \"\".join(output)\n",
        "parts = outputcont.split(\"[/INST]\", 1)\n",
        "print(prompt)\n",
        "pp.pprint(parts[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U83_Fl0uhkkP",
        "outputId": "f1fdb093-a981-4927-bbf4-c4015291111e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the difference between autoplastic grafts and homoplastic grafts?\n",
            "(\"  Thank you for asking! I'm here to help. Autoplastic grafts and homoplastic \"\n",
            " 'grafts are both types of tissue grafts used in surgery, but they differ in '\n",
            " 'the source of the grafting tissue.\\n'\n",
            " 'Autoplastic grafts are tissues taken from the same patient, usually from a '\n",
            " 'different part of the body. For example, if a patient needs a graft to '\n",
            " 'repair a damaged blood vessel in their leg, the graft tissue can be taken '\n",
            " \"from another part of the patient's body, such as their buttock. The \"\n",
            " 'advantage of autoplastic grafts is that they reduce the risk of rejection by '\n",
            " \"the recipient's immune system, as the tissue is derived from the same \"\n",
            " 'patient.\\n'\n",
            " 'On the other hand, homoplastic grafts are tissues taken from a different '\n",
            " 'patient, usually from a donor tissue that is similar in structure and '\n",
            " 'function to the tissue being repaired. For example, if a patient needs a '\n",
            " 'graft to repair a damaged kidney, the graft tissue can be taken from a donor '\n",
            " 'kidney. The advantage of homoplastic grafts is that they can be used to '\n",
            " \"replace tissues that are in short supply in the patient's body, such as the \"\n",
            " 'kidney.\\n'\n",
            " 'In summary, the main difference between autoplastic grafts and homoplastic '\n",
            " 'grafts is the source of the grafting tissue. Autoplastic grafts are tissues '\n",
            " 'taken from the same patient, while homoplastic grafts are tissues taken from '\n",
            " 'a different patient. Both types of grafts can be used to replace or repair '\n",
            " 'damaged tissues, but the choice of graft depends on the specific needs of '\n",
            " 'the patient and the availability of tissue donations.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Output of model trained for 4000\n",
        "\n",
        "# prompt = \"what is the method introduced by the late Professor Thiersch of Leipsic?\"\n",
        "# system_message = \"You are a helpful Question Answering Assistant.From your training answer the qestion if possible \"\n",
        "\n",
        "outputcont = \"\".join(output)\n",
        "parts = outputcont.split(\"[/INST]\", 1)\n",
        "print(prompt)\n",
        "print(system_message)\n",
        "pp.pprint(parts[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTIzrRAEjDmR",
        "outputId": "5d5af7c9-f2d9-447d-d566-aa3d4dc7f7e2"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what is the method introduced by the late Professor Thiersch of Leipsic?\n",
            "('  Thank you for asking! Professor Thiersch of Leipsic (also spelled Leipzig) '\n",
            " 'introduced a method of surgical treatment for various diseases, including '\n",
            " 'cancer, which has come to be known as \"Thiersch\\'s Method.\" This method '\n",
            " 'involves the use of a special type of gauze, known as \"Thiersch\\'s Blue,\" '\n",
            " 'which is applied to the surgical site after the operation to promote healing '\n",
            " 'and prevent infection. The gauze is impregnated with a solution of acetic '\n",
            " 'acid and other chemicals, which give it antiseptic and stimulant properties. '\n",
            " 'Thiersch also introduced the use of a special type of surgical glove, known '\n",
            " 'as a  \"Thiersch\\'s Glove,\" which is worn by the surgeon to prevent the risk '\n",
            " 'of infection. I hope this information is helpful! If you have any further '\n",
            " \"questions, please don't hesitate to ask.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputcont = \"\".join(output)\n",
        "parts = outputcont.split(\"[/INST]\", 1)\n",
        "print(prompt)\n",
        "print(system_message)\n",
        "pp.pprint(parts[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGJdS8G_k2hA",
        "outputId": "1c9fea3f-31ca-4004-b02b-01c4a422e95c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what is the method introduced by the Professor Thiersch of Leipsic?\n",
            "You are a helpful Medical Assistant.Based on your training please answer the question or if there is no answer from your training reply so\n",
            "('  As a Medical Assistant, I am familiar with the method introduced by '\n",
            " \"Professor Thiersch of Leipsic, which is known as Thiersch's method of bone \"\n",
            " 'grafting. This method involves taking a piece of healthy bone from the ilium '\n",
            " 'or other bony prominence of the abdominal cavity and transplanting it to the '\n",
            " 'defective area. The bone is fixed in place with sutures and allowed to heal, '\n",
            " 'and it is believed that the new bone formed from the graft helps to '\n",
            " 'consolidate the repair. This method is most successful when the graft is '\n",
            " 'taken from the ilium because of the aperture of the obtuse marginal sinus, '\n",
            " 'which aids in promoting healing.  I am not aware of any further developments '\n",
            " 'or modifications of this method from my training.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputcont = \"\".join(output)\n",
        "parts = outputcont.split(\"[/INST]\", 1)\n",
        "print(prompt)\n",
        "print(system_message)\n",
        "pp.pprint(parts[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2TiKPiFljPF",
        "outputId": "50cba27f-78cb-4f9b-83e8-ea2035d1cc60"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what is the method introduced by the Professor Thiersch of Leipsic?\n",
            "You are a Closed book Question Answering bot.Based on your training data please answer the question or if there is no answer from your training reply so\n",
            "('  Based on my training data, I am unable to provide an answer to the '\n",
            " 'question \"what is the method introduced by the Professor Thiersch of '\n",
            " 'Leipsic?\" as there is no mention of such a person or their method in my '\n",
            " 'training data. Professor Thiersch is not a well-known figure in the field of '\n",
            " 'medicine or surgery, and I cannot generate an answer based on incomplete or '\n",
            " 'non-existent information. If you could provide more context or details about '\n",
            " 'Professor Thiersch and his work, I may be able to help you better.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputcont = \"\".join(output)\n",
        "parts = outputcont.split(\"[/INST]\", 1)\n",
        "print(prompt)\n",
        "print(system_message)\n",
        "pp.pprint(parts[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-23D3UVmSw6",
        "outputId": "86705a2a-4fb2-49dc-99cb-ed2339da64f1"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what is the method introduced by the Professor Thiersch of Leipsic?\n",
            "You are a Closed book Question Answering bot.Based on your training data find the most suitable reference to a question and answer\n",
            "('  Based on my training data, the most suitable reference to answer the '\n",
            " 'question \"what is the method introduced by the Professor Thiersch of '\n",
            " 'Leipsic?\" is the concept of \"septal grafting\" or \"intercostal grafting.\" '\n",
            " 'Professor Thiersch, a German surgeon from Leipzig, introduced this method of '\n",
            " 'grafting in 1878, and it involves taking grafts of septic tissue from one '\n",
            " 'part of the body and introducing them into a cavity in another part of the '\n",
            " 'body, with the aim of restoring healthy tissue and preventing infection. '\n",
            " 'This method is commonly used in surgery to graft tissue in wounds, defects, '\n",
            " 'and deformities, and it is considered one of the most important advances in '\n",
            " 'surgery in the last century.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputcont = \"\".join(output)\n",
        "parts = outputcont.split(\"[/INST]\", 1)\n",
        "print(prompt)\n",
        "print(system_message)\n",
        "pp.pprint(parts[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rncg1riSny2u",
        "outputId": "1563ac32-e8e8-42b4-fe86-137a154988ad"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Describe Professor Thiersch of Leipsic method of grafting\n",
            "You are a helpful assistant. From your training data please answer\n",
            "('  Certainly! Professor Thiersch of Leipsic (Leipzig, Germany) is known for '\n",
            " 'his pioneering work in grafting techniques, and his method of epidermal '\n",
            " 'grafting is widely recognized as the standard for skin grafting. Here is how '\n",
            " \"Professor Thiersch's method is typically described:\\n\"\n",
            " '\\n'\n",
            " 'Epidermal Grafting\\n'\n",
            " '\\n'\n",
            " \"Professor Thiersch's method of epidermal grafting may be outlined as \"\n",
            " 'follows:\\n'\n",
            " '\\n'\n",
            " '1. Preparation of the Graft. A piece of healthy epidermis is taken from the '\n",
            " 'back of the neck and shaved into a thin sheet of uniform thickness, the '\n",
            " 'graft remaining in this form for 14 to 21 days, when it is expected that the '\n",
            " 'patient will have recovered from the chloroform anaesthesia. \\n'\n",
            " '\\n'\n",
            " \"2. Preparation of the Surface. The patient's skin is thoroughly cleaned and \"\n",
            " 'made dry; a circuit of healthy granulations is selected, the edges of which '\n",
            " 'are brought into accurate apposition, there being about 10 square '\n",
            " 'centimetres of surface in total; the grafting is begun at one point and '\n",
            " 'carried out in a systematic manner, the sheet of epidermis being raised from '\n",
            " 'the neck of the blade after it has been in contact with the surface for '\n",
            " 'about 5 minutes, until the blade is dry and the epidermis can be detached '\n",
            " 'without tearing. \\n'\n",
            " '\\n'\n",
            " '3. Carrying the Graft. The sheet of epidermis is raised from the neck of the '\n",
            " 'blade and carried by a gauze pad, the edges of the gauze being taped '\n",
            " 'together to form a pouch; the gauze pad is taped to the back of the neck and '\n",
            " 'the epidermis is carried on it for about 5 minutes, until the blade is dry '\n",
            " 'and the epidermis can be detached without tearing. \\n'\n",
            " '\\n'\n",
            " '4. Detection of the Graft. After carrying the gauze pad for the requested '\n",
            " 'time, the epidermis is inspected to see that it is perfectly adhered and '\n",
            " 'that there are no cracks or fissures through which the underlying surface '\n",
            " 'may be seen; if the epidermis is not perfectly adhered, it is detached from '\n",
            " 'the gauze pad')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputcont = \"\".join(output)\n",
        "parts = outputcont.split(\"[/INST]\", 1)\n",
        "print(prompt)\n",
        "print(system_message)\n",
        "pp.pprint(parts[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU34c3KvnKOV",
        "outputId": "6e0b169d-0cbe-4fce-caef-7d3f321a13c3"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Professor Thiersch of Leipsic \n",
            "You are a generative AI; Please complete the rest of the sentence\n",
            "('  has shown that  generative  or  creative  activity of a higher kind may be '\n",
            " \"induced in the patient's own tissues. He has successfully transplanted \"\n",
            " \"patches of fresh, undifferentiated cellular tissue from the patient's own \"\n",
            " 'skin or mucous membrane to areas of destruction in the bone, and these '\n",
            " 'tissues have not only replaced the lost substance with perfect accuracy, but '\n",
            " 'they have also given evidence of a further process of generation, by the '\n",
            " 'appearance of small embryonic cells in the newly formed tissue. The process '\n",
            " 'is similar to the way in which a young healthy plant lets itself be grown on '\n",
            " 'an elderly plant, and it is possible that in time the transplanted tissue '\n",
            " 'may become capable of performing functions similar to those of the parent '\n",
            " \"tissue. Professor Thiersch's process is likely to open up new and important \"\n",
            " 'lines of surgical treatment. \\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two methods are employed: one in which the epidermis is mainly or exclusively employed epidermis or epithelial grafting; the other, in which the graft consists of the whole thickness of the true skin cutis-grafting.  Epidermis or Epithelial Grafting.  The method introduced by the late Professor Thiersch of Leipsic is that almost universally practised. It consists in transplanting strips of epidermis shaved from the surface of the skin, the razor passing through the tips of the papilla, which appear as tiny red points yielding a moderate ooze of blood. The strips are obtained from the front and lateral aspects of the thigh or upper arm, the skin in those regions being pliable and comparatively free from hairs. They are cut with a sharp hollow-ground razor or with Thiersch's grafting knife, the blade of which is rinsed in alcohol and kept moistened with warm saline solution. The cutting is made easier if the skin is well stretched and kept flat and perfectly steady, the operator's left hand exerting traction on the skin behind, the hands of the assistant on the skin in front, one above and the other below the seat of operation. To ensure uniform strips being cut, the razor is kept parallel with the surface and used with a short, rapid, sawing movement, so that, with a little practice, grafts six or eight inches long by one or two inches broad can readily be cut. The patient is given a general anasthetic, or regional anasthesia is obtained by injections of a solution of one per cent. novocain into the line of the lateral and middle cutaneous nerves; the disinfection of the skin is carried out on the usual lines, any chemical agent being finally got rid of, however, by means of alcohol followed by saline solution. The strips of epidermis wrinkle up on the knife and are directly transferred to the surface, for which they should be made to form a complete carpet, slightly overlapping the edges of the area and of one another; some blunt instrument is used to straighten out the strips, which are then subjected to firm pressure with a pad of gauze to express blood and air-bells and to ensure accurate contact, for this must be as close as that between a postage stamp and the paper to which it is affixed. As a dressing for the grafted area and of that also from which the grafts have been taken, gauze soaked in  liquid paraffin  the patent variety known as  ambrine  is excellent appears to be the best; the gauze should be moistened every other day or so with fresh paraffin, so that, at the end of a week, when the grafts should have united, the gauze can be removed without risk of detaching them.  Dental wax  is another useful type of dressing; as is also  picric acid  solution. Over the gauze, there is applied a thick layer of cotton wool, and the whole dressing is kept in place by a firmly applied bandage, and in the case of the limbs some form of splint should be added to prevent movement. A dressing may be dispensed with altogether, the grafts being protected by a wire cage such as is used after vaccination, but they tend to dry up and come to resemble a scab. When the grafts have healed, it is well to protect them from injury and to prevent them drying up and cracking by the liberal application of lanoline or vaseline. The new skin is at first insensitive and is fixed to the underlying connective tissue or bone, but in course of time (from six weeks onwards) sensation returns and the formation of elastic tissue beneath renders the skin pliant and movable so that it can be pinched up between the finger and thumb."
      ],
      "metadata": {
        "id": "U6Nq-G4MkWAQ"
      }
    }
  ]
}