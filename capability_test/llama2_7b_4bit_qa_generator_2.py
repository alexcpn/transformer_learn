# -*- coding: utf-8 -*-
"""llama2-7b-4bit-qa_generator_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lZdGovQbEKwEmKzSWfx1JMnmdPNphgjz
"""
import traceback
from lib_llm import LLAMa2Q,sliding_window
import re
import locale
locale.getpreferredencoding = lambda: "UTF-8"

pattern = r"(?:Q:|Question:)\s*(.*?)\n(?:A:|Answer:)\s*(.*?)(?=\n(?:Q:|Question:)|\n$)"
  




if __name__ == "__main__":

    system_message = """You are a smart AI assistant that can create question and answers based on the context"""

    filename = './output.mdx'
    #filename = '../data/small_3.txt'

    print("Going to load the llama2 7b model ...")
    llam2_4bit = LLAMa2Q(model_name="meta-llama/Llama-2-7b-chat-hf",q4bitA=True)
    print("Loaded LLama2 7b model")

    #chunks = sliding_window(filename)
    chunk = """prompt=Ceph Commands
    Run any ceph command with `kubectl rook-ceph ceph <args>`. For example, get the Ceph status:
    ```
    kubectl rook-ceph ceph status

    ```
    Output:
    ```
    cluster:
    id:     a1ac6554-4cc8-4c3b-a8a3-f17f5ec6f529
    health: HEALTH_OK

    services:
    mon: 3 daemons, quorum a,b,c (age 11m)
    mgr: a(active, since 10m)
    mds: 1/1 daemons up, 1 hot standby
    osd: 3 osds: 3 up (since 10m), 3 in (since 8d)

    data:
    volumes: 1/1 healthy
    pools:   6 pools, 137 pgs
    objects: 34 objects, 4.1 KiB
    usage:   58 MiB used, 59 GiB / 59 GiB avail
    pgs:     137 active+clean

    io:
    client:   1.2 KiB/s rd, 2 op/s rd, 0 op/s wr
    Reference: Ceph Status
    ```
    Debug ModeÂ¶
    Debug mode can be useful when a MON or OSD needs advanced maintenance operations that require the daemon to be stopped. 
    Ceph tools such as ceph-objectstore-tool, ceph-bluestore-tool, or ceph-monstore-tool are commonly used in these scenarios.
    Debug mode will set up the MON or OSD so that these commands can be run.

    Start the debug pod for mon b
    ```
    kubectl rook-ceph debug start rook-ceph-mon-b
    ```
    Stop the debug pod for mon b

    ```
    kubectl rook-ceph debug stop rook-ceph-mon-b
    ```
    """
    chunks=[chunk]

    for index, chunk in enumerate(chunks):
        #print(f"prompt={chunk}")
        #print("--"*80)
        #continue
        promt =f"""context = '{chunk}'
        Create 20 different questions and answers for the above context, format like
        Q:
        A:
        """
        prompt_template = llam2_4bit.create_prompt(promt,system_message)
        try:
            output = llam2_4bit.generate_ouputput(prompt_template)
            response =llam2_4bit.get_chat_response(output)
            print(response)
            matches = parse_response_out(response)
            with open("noc_qa_data2.txt", "a", encoding='utf-8') as myfile:
                for index, (question, answer) in enumerate(matches):
                    out = f"<s>[INST] Source:2212AA {question} [/INST] Source:2212AA {answer} </s>\n"
                    myfile.write(out)
                
        except Exception :
            print(traceback.format_exc())

